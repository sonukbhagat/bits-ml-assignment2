{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning - Assignment 2\n",
        "BITS ID: 2025AA05952\n",
        "\n",
        "Name: SONU KUMAR BHAGAT\n",
        "\n",
        "Email: 2025aa05952@wilp.bits-pilani.ac.in\n",
        "\n",
        "This notebook compares the following six models for a classification task:\n",
        "\n",
        "Logistic Regression\n",
        "Decision Tree Classifier\n",
        "K-Nearest Neighbor Classifier\n",
        "Naive Bayes Classifier\n",
        "Random Forest (Ensemble)\n",
        "XGBoost (Ensemble)\n",
        "Dataset:\n",
        "\"Early Stage Diabetes Risk Prediction\" dataset from UCI https://archive.ics.uci.edu/dataset/529/early+stage+diabetes+risk+prediction+dataset"
      ],
      "metadata": {
        "id": "-sv_VA3-4Vx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDrksl-qJEpr",
        "outputId": "c0c6f4b9-2000-4fbb-8a66-20614dabb4aa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2026.1.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RW0VZbictxRA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch Dataset"
      ],
      "metadata": {
        "id": "ugEY5wVtJihl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fetching dataset from UCI...\")\n",
        "dataset = fetch_ucirepo(id=529)\n",
        "X_raw = dataset.data.features.copy()\n",
        "y_raw = dataset.data.targets.copy()"
      ],
      "metadata": {
        "id": "jXfZ2sZ3JmCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0da620f-52b3-4fee-b0ce-69a88f45af89"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching dataset from UCI...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Exploration"
      ],
      "metadata": {
        "id": "_PLYjsmnMOVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Dataset Information ---\")\n",
        "\n",
        "# 1. Shape and Size\n",
        "print(f\"Dataset Shape: {X_raw.shape}\")\n",
        "print(f\"Total Instances: {len(X_raw)}\")\n",
        "print(f\"Total Features: {X_raw.shape[1]}\")\n",
        "\n",
        "# 2. Column Names and Types\n",
        "print(\"\\n--- Column List and Types ---\")\n",
        "print(X_raw.dtypes)\n",
        "\n",
        "# 3. Check for Null Values\n",
        "print(\"\\n--- Null Value Check ---\")\n",
        "null_counts = X_raw.isnull().sum()\n",
        "if null_counts.sum() == 0:\n",
        "    print(\"No missing values found in the dataset.\")\n",
        "else:\n",
        "    print(null_counts[null_counts > 0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jiKv6XCMQsk",
        "outputId": "99ca2a48-55f7-49c0-d68c-e2ba48c0fc96"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dataset Information ---\n",
            "Dataset Shape: (520, 16)\n",
            "Total Instances: 520\n",
            "Total Features: 16\n",
            "\n",
            "--- Column List and Types ---\n",
            "age                    int64\n",
            "gender                object\n",
            "polyuria              object\n",
            "polydipsia            object\n",
            "sudden_weight_loss    object\n",
            "weakness              object\n",
            "polyphagia            object\n",
            "genital_thrush        object\n",
            "visual_blurring       object\n",
            "itching               object\n",
            "irritability          object\n",
            "delayed_healing       object\n",
            "partial_paresis       object\n",
            "muscle_stiffness      object\n",
            "alopecia              object\n",
            "obesity               object\n",
            "dtype: object\n",
            "\n",
            "--- Null Value Check ---\n",
            "No missing values found in the dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-processing"
      ],
      "metadata": {
        "id": "LGOZgOeFJuN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('model', exist_ok=True)\n",
        "encoders = {}\n",
        "\n",
        "# Process Features (Converting Yes/No, Male/Female to 0/1)\n",
        "X = X_raw.copy()\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'object':\n",
        "        le = LabelEncoder()\n",
        "        X[col] = le.fit_transform(X[col])\n",
        "        encoders[col] = le\n",
        "\n",
        "# Process Target (Positive/Negative to 1/0)\n",
        "target_le = LabelEncoder()\n",
        "y = target_le.fit_transform(y_raw.values.ravel())\n",
        "encoders['target'] = target_le\n",
        "\n",
        "# Scale Age (Crucial for kNN and Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X['age'] = scaler.fit_transform(X[['age']]) # Changed 'Age' to 'age'\n",
        "\n",
        "# Save all encoders and scaler for the Streamlit App to use\n",
        "with open('model/encoders.pkl', 'wb') as f:\n",
        "    pickle.dump(encoders, f)\n",
        "with open('model/scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "# 3. Handle Imbalance (SMOTE) & Split\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X, y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "qEBtIPREP-xV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model dictionary"
      ],
      "metadata": {
        "id": "9zCnmNcvJ9hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"kNN\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"XGBoost\": XGBClassifier()\n",
        "}"
      ],
      "metadata": {
        "id": "Q_03NBeCKAGv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Evaluate"
      ],
      "metadata": {
        "id": "nE3HSpGEKHbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('model', exist_ok=True)\n",
        "results = []\n",
        "\n",
        "# Import necessary metrics here to ensure they are available within the loop scope\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, matthews_corrcoef\n",
        "\n",
        "print(\"Training models...\")\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    with open(f'model/{name.replace(\" \", \"_\").lower()}.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "    metrics = {\n",
        "        \"ML Model Name\": name,\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"AUC\": roc_auc_score(y_test, y_prob),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1\": f1_score(y_test, y_pred),\n",
        "        \"MCC\": matthews_corrcoef(y_test, y_pred)\n",
        "    }\n",
        "    results.append(metrics)"
      ],
      "metadata": {
        "id": "a54_PwhzKJ5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78f868b-049e-466a-e346-4bbe30e20bac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training models...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display comparison table"
      ],
      "metadata": {
        "id": "OckEcYx6KYYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_results = pd.DataFrame(results)\n",
        "print(df_results.to_markdown(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR-aGY82KeqU",
        "outputId": "ee2e9a3b-80b1-4568-82b2-b84de32d53eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ML Model Name       |   Accuracy |      AUC |   Precision |   Recall |       F1 |      MCC |\n",
            "|:--------------------|-----------:|---------:|------------:|---------:|---------:|---------:|\n",
            "| Logistic Regression |   0.953125 | 0.995357 |    0.983871 | 0.924242 | 0.953125 | 0.908113 |\n",
            "| Decision Tree       |   0.984375 | 0.98436  |    0.984848 | 0.984848 | 0.984848 | 0.968719 |\n",
            "| kNN                 |   0.914062 | 0.97544  |    1        | 0.833333 | 0.909091 | 0.841286 |\n",
            "| Naive Bayes         |   0.898438 | 0.974096 |    0.895522 | 0.909091 | 0.902256 | 0.796675 |\n",
            "| Random Forest       |   1        | 1        |    1        | 1        | 1        | 1        |\n",
            "| XGBoost             |   0.96875  | 0.998534 |    0.984375 | 0.954545 | 0.969231 | 0.937958 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save sample test.csv for Streamlit"
      ],
      "metadata": {
        "id": "ol3yjJKYKuJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_full_raw = pd.concat([X_raw, y_raw], axis=1)\n",
        "target_col = y_raw.columns[0]\n",
        "df_pos = df_full_raw[df_full_raw[target_col] == 'Positive'].head(25)\n",
        "df_neg = df_full_raw[df_full_raw[target_col] == 'Negative'].head(25)\n",
        "raw_test_sample = pd.concat([df_pos, df_neg]).sample(frac=1, random_state=42)\n",
        "raw_test_sample.to_csv('test_sample.csv', index=False)\n",
        "\n",
        "print(\"\\n--- Process Complete ---\")\n",
        "print(\"✅ 6 Models saved in /model/ folder\")\n",
        "print(\"✅ Preprocessing artifacts (scaler/encoders) saved\")\n",
        "print(\"✅ Balanced 'test_sample.csv' created for app testing\")"
      ],
      "metadata": {
        "id": "YnEPxjy2KyZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0650b24-1b80-4eb3-9519-65ab00e842bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Process Complete ---\n",
            "✅ 6 Models saved in /model/ folder\n",
            "✅ Preprocessing artifacts (scaler/encoders) saved\n",
            "✅ Balanced 'test_sample.csv' created for app testing\n"
          ]
        }
      ]
    }
  ]
}