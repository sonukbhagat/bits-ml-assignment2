{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning - Assignment 2\n",
        "BITS ID: 2025AA05952\n",
        "\n",
        "Name: SONU KUMAR BHAGAT\n",
        "\n",
        "Email: 2025aa05952@wilp.bits-pilani.ac.in\n",
        "\n",
        "This notebook compares the following six models for a classification task:\n",
        "\n",
        "Logistic Regression\n",
        "Decision Tree Classifier\n",
        "K-Nearest Neighbor Classifier\n",
        "Naive Bayes Classifier\n",
        "Random Forest (Ensemble)\n",
        "XGBoost (Ensemble)\n",
        "Dataset:\n",
        "\"Early Stage Diabetes Risk Prediction\" dataset from UCI https://archive.ics.uci.edu/dataset/529/early+stage+diabetes+risk+prediction+dataset"
      ],
      "metadata": {
        "id": "-sv_VA3-4Vx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDrksl-qJEpr",
        "outputId": "cd1a8823-c50f-4783-8d6d-3673bb83fc02"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2026.1.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RW0VZbictxRA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "class_nb = __import__('sklearn.naive_bayes', fromlist=['GaussianNB'])\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch Dataset"
      ],
      "metadata": {
        "id": "ugEY5wVtJihl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = fetch_ucirepo(id=529)\n",
        "X = dataset.data.features.copy()\n",
        "y = dataset.data.targets.copy()"
      ],
      "metadata": {
        "id": "jXfZ2sZ3JmCq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Exploration"
      ],
      "metadata": {
        "id": "_PLYjsmnMOVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Dataset Information ---\")\n",
        "\n",
        "# 1. Shape and Size\n",
        "print(f\"Dataset Shape: {X.shape}\")\n",
        "print(f\"Total Instances: {len(X)}\")\n",
        "print(f\"Total Features: {X.shape[1]}\")\n",
        "\n",
        "# 2. Column Names and Types\n",
        "print(\"\\n--- Column List and Types ---\")\n",
        "print(X.dtypes)\n",
        "\n",
        "# 3. Check for Null Values\n",
        "print(\"\\n--- Null Value Check ---\")\n",
        "null_counts = X.isnull().sum()\n",
        "if null_counts.sum() == 0:\n",
        "    print(\"No missing values found in the dataset.\")\n",
        "else:\n",
        "    print(null_counts[null_counts > 0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jiKv6XCMQsk",
        "outputId": "946b278d-aebe-43d7-e4d1-36bd50a86a83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dataset Information ---\n",
            "Dataset Shape: (520, 16)\n",
            "Total Instances: 520\n",
            "Total Features: 16\n",
            "\n",
            "--- Column List and Types ---\n",
            "age                    int64\n",
            "gender                object\n",
            "polyuria              object\n",
            "polydipsia            object\n",
            "sudden_weight_loss    object\n",
            "weakness              object\n",
            "polyphagia            object\n",
            "genital_thrush        object\n",
            "visual_blurring       object\n",
            "itching               object\n",
            "irritability          object\n",
            "delayed_healing       object\n",
            "partial_paresis       object\n",
            "muscle_stiffness      object\n",
            "alopecia              object\n",
            "obesity               object\n",
            "dtype: object\n",
            "\n",
            "--- Null Value Check ---\n",
            "No missing values found in the dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-processing"
      ],
      "metadata": {
        "id": "LGOZgOeFJuN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE # Optional but recommended for better marks\n",
        "\n",
        "# --- ENHANCED PREPROCESSING ---\n",
        "\n",
        "# 1. Feature Encoding\n",
        "# The dataset contains 'Yes'/'No' and 'Male'/'Female'. We must convert these to 0/1.\n",
        "le = LabelEncoder()\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'object':\n",
        "        X[col] = le.fit_transform(X[col])\n",
        "\n",
        "# Encode the Target (Positive/Negative)\n",
        "y = le.fit_transform(y.values.ravel())\n",
        "\n",
        "# 2. Feature Scaling\n",
        "# 'Age' is in the range of 16-90, while others are 0-1.\n",
        "# Scaling helps kNN and Logistic Regression converge faster and perform better.\n",
        "scaler = StandardScaler()\n",
        "X['age'] = scaler.fit_transform(X[['age']])\n",
        "\n",
        "# 3. Handling Class Imbalance (SMOTE)\n",
        "# If one class (Positive/Negative) is much smaller, the model will be biased.\n",
        "# This creates synthetic samples to balance the dataset.\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "print(f\"Original dataset shape: {X.shape}\")\n",
        "print(f\"Resampled dataset shape: {X_resampled.shape}\")\n",
        "\n",
        "# Split the resampled data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEBtIPREP-xV",
        "outputId": "57f2a599-e893-4483-fc8b-15eff699480b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (520, 16)\n",
            "Resampled dataset shape: (640, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model dictionary"
      ],
      "metadata": {
        "id": "9zCnmNcvJ9hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"kNN\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": class_nb.GaussianNB(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"XGBoost\": XGBClassifier()\n",
        "}"
      ],
      "metadata": {
        "id": "Q_03NBeCKAGv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Evaluate"
      ],
      "metadata": {
        "id": "nE3HSpGEKHbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('model', exist_ok=True)\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else y_pred\n",
        "\n",
        "    metrics = {\n",
        "        \"ML Model Name\": name,\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"AUC\": roc_auc_score(y_test, y_prob),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1\": f1_score(y_test, y_pred),\n",
        "        \"MCC\": matthews_corrcoef(y_test, y_pred)\n",
        "    }\n",
        "    results.append(metrics)"
      ],
      "metadata": {
        "id": "a54_PwhzKJ5e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save models"
      ],
      "metadata": {
        "id": "RnkAqm-aKTs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "# Create a folder to store the models if it doesn't exist\n",
        "model_dir = 'model'\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "# Assuming 'models' is your dictionary of trained objects from the previous step\n",
        "for name, model in models.items():\n",
        "    # Create a clean filename (e.g., \"Logistic Regression\" -> \"logistic_regression.pkl\")\n",
        "    filename = f\"{name.replace(' ', '_').lower()}.pkl\"\n",
        "    file_path = os.path.join(model_dir, filename)\n",
        "\n",
        "    # Save the model\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "    print(f\"✅ Saved: {file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0SJffFmN27G",
        "outputId": "d949c598-b6eb-4203-9e59-9d1ed2b00a36"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved: model/logistic_regression.pkl\n",
            "✅ Saved: model/decision_tree.pkl\n",
            "✅ Saved: model/knn.pkl\n",
            "✅ Saved: model/naive_bayes.pkl\n",
            "✅ Saved: model/random_forest.pkl\n",
            "✅ Saved: model/xgboost.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display comparison table"
      ],
      "metadata": {
        "id": "OckEcYx6KYYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_results = pd.DataFrame(results)\n",
        "print(df_results.to_markdown(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR-aGY82KeqU",
        "outputId": "772e9f9e-7e4f-43cf-d553-5c629e1e8414"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ML Model Name       |   Accuracy |      AUC |   Precision |   Recall |       F1 |      MCC |\n",
            "|:--------------------|-----------:|---------:|------------:|---------:|---------:|---------:|\n",
            "| Logistic Regression |   0.953125 | 0.995357 |    0.983871 | 0.924242 | 0.953125 | 0.908113 |\n",
            "| Decision Tree       |   0.984375 | 0.98436  |    0.984848 | 0.984848 | 0.984848 | 0.968719 |\n",
            "| kNN                 |   0.914062 | 0.97544  |    1        | 0.833333 | 0.909091 | 0.841286 |\n",
            "| Naive Bayes         |   0.898438 | 0.974096 |    0.895522 | 0.909091 | 0.902256 | 0.796675 |\n",
            "| Random Forest       |   1        | 1        |    1        | 1        | 1        | 1        |\n",
            "| XGBoost             |   0.96875  | 0.998534 |    0.984375 | 0.954545 | 0.969231 | 0.937958 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save sample test.csv for Streamlit"
      ],
      "metadata": {
        "id": "ol3yjJKYKuJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = X_test.copy()\n",
        "test_data['target'] = y_test\n",
        "test_data.to_csv('test_sample.csv', index=False)"
      ],
      "metadata": {
        "id": "YnEPxjy2KyZk"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}